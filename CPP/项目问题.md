# CMU15-445 介绍
    这个项目随着课程主要是完成一个mini数据库，其中主要包括，缓存、B+树索引、查询执行、并发控制；其中主要工作量在前两部分，后面两个部分更多的是理论；

# 执行流程 
预处理 -> Parser（生成语法树） -> Binder（将名字绑定到数据库实体) -> Planner(生成初步查询计划) -> Optimizer（优化查询计划, 制定规则）-> Executor(执行算子) 



## 缓存
1. 缓存池提供两个主要功能缓存Page， 剔除Page；这俩功能由可扩展哈希， LRU-K 算法完成；
# 可扩展哈希-其最大的特点是支持动态扩容 - 桶的数量可变
2. 接下来先介绍可扩展哈希 - bucket，gdepth， ldepth
3. depth意义 - k -> 去 hask(Key) 的k位， 并且此时一定有 2k次方个桶；ruo l==g -> 此时只有一个指针指向这个桶
4. 可扩展哈希与拉链式哈希，在 K 中，不同的指针可以指向同一个 bucket， L 中每个指针对应一个 bucket。
5. 当桶的容量满了-会发生split操作
        1. l==g: T*2， 并且全部复制；
        2. l!=g: 新创建两个桶，把原先的同理的重新Hash
        3. 递归操作
6. 优点 实型数据规模的变化，提高扩展性；

# LRU-K
1. 用于buffer满，驱逐page的算法
2. 使用std::map, 与std::list 实现
两个链表 代表  < K, >= K 次访问
map <frame_id, list迭代器>
新的放在结尾；剔除的时候从连白头开始找
当访问次数达到K，则放入另一个链表中；

# 重要数据成员
    pages - 页数组， page_table_<pid, fid> - 哈希表, free_list_ <frame_id_t>

# 查询流程
    1. 首先查缓存 - page_table_；
    2. 否则从 free_list中找一个空闲的frame，找到退出；
    3. 否则进行 LRU-K 算法剔除一个页面；

# - LRU-K算法的应用场景？ LRU-K算法相对于LRU算法的优势有哪些 ？
    1. 用于置换算法 - 操作系统，数据库；
    2. 更加精细，更好地应对周期性地访问，解决缓存污染(周期访问，大量历史数据)；

# 直接I/O 优点 - 最大的优点就是减少操作系统缓冲区和用户地址空间的拷贝次数。降低了CPU的开销，和内存带宽
# 直接I/O 缺点 - 应用程序没有控制好读写，将会导致磁盘读写的效率低下
# 使用场景
    1. 需要绕过操作系统缓存
    2. 大量数据的高性能IO
    3. 文件同步

# 当应用程序需要直接访问文件而不经过操作系统页高速缓冲存储器的时候，它打开文件的时候需要指定 O_DIRECT 标识符

# 
1. 时间复杂度，除了调整大小O(n)，其余都是O(1);


## B+树索引 - 线程安全

1. B+树和B树的区别？
    1. 结构：
        1. B树每个节点包含一定数量的键值对，分支节点存储键值和指向子树的指针，叶子节点存储键值和数据。B树的所有叶子节点具有相同的深度。 
        2. B+树也是平衡树，与B树不同的是，B+树的所有数据都存储在叶子节点上，内部节点只包含键值和子树的指针。B+树的叶子节点形成了一个链表，方便范围查询。
    2. 数据存储
        1. B树的叶子节点存储数据，且每个叶子节点都包含了所有的关键字。
        2. B+树的叶子节点存储所有数据，内部节点只存储键值，不存储数据

2. 为啥B+树更适合数据库索引的实现 - 支持顺序查找
    1. 范围查询效率高，最底层是个有序链表；
    2. 树的高度较小，提升查询效率；
    3. 适合磁盘顺序存储， 减少IO， ；
    4. 全表扫描 - 需要顺序遍历；
    5. 插入删除，分裂，合并少，效率高；

3. 具体看 数据库里面的总结

## 查询执行 - 理解原理
1. 在火山模型中，查询计划的生成过程可以看作是从输入表节点开始，通过选择、投影、连接等基本操作符节点，逐步生成更复杂的中间结果，最终形成一个完整的执行计划。这个执行计划会包括一系列的物理操作符节点，描述了实际执行查询的具体步骤

每个算子都有 Init() 和 Next() 两个方法。Init() 对算子进行初始化工作。Next() 则是向下层算子请求下一条数据。当 Next() 返回 false 时，则代表下层算子已经没有剩余数据，迭代结束。可以看到，火山模型一次调用请求一条数据，占用内存较小，但函数调用开销大，特别是虚函数调用造成 cache miss 等问题。

从根节点开始，不断 pull 子节点的 数据；
Insert 时，直接将 tuple 追加至 table 尾部。Delete 时，并不是直接删除，而是将 tuple 标记为删除状态，也就是逻辑删除

# 就说支持这些吧
Seqscan， Insert， Delete
Sort()，Aggregation 的 Init() 函数中，我们就要将所有结果全部计算出来


2. 为什么要使用火山模型？有什么优点
    1. 层次结构清晰， 模块化的设计；
    2. 存储中间结果，减少重复计算；
3. 缺点
    1. 不适合流式处理

## 事务管理 
# Lock Manager：锁管理器，利用 2PL 实现并发控制。支持 REPEATABLE_READ、READ_COMMITTED 和 READ_UNCOMMITTED 三种隔离级别，支持 SHARED、EXCLUSIVE、INTENTION_SHARED、INTENTION_EXCLUSIVE 和 SHARED_INTENTION_EXCLUSIVE 五种锁，支持 table 和 row 两种锁粒度，支持锁升级。Project 4 重点部分。
# Deadlock Detection：死锁检测，运行在一个 background 线程，每间隔一定时间检测当前是否出现死锁，并挑选合适的事务将其 abort 以解开死锁。
# Concurrent Query Execution：修改之前实现的 SeqScan、Insert 和 Delete 算子，加上适当的锁以实现并发的查询

# 意向锁

1. REPEATABLE_READ：可以重复读
1. READ_COMMITTED：读已提交
1. READ_UNCOMMITTED： 两次读的东西不一样


# 2PL 前一阶段只允许枷锁，后一阶段只允许释放锁 - Growing - Shrink
# 问题 - 死锁，效率低